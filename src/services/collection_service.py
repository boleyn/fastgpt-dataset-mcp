"""
Collectionç®¡ç†æœåŠ¡
"""

from typing import List
from urllib.parse import quote
from ..api_client import api_client
from ..models import DataChunk, CollectionInfo
from ..logger import collection_logger
from .format_utils import FormatUtils


class CollectionService:
    """Collectionç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.api_client = api_client
    
    async def view_collection_content(self, collection_id: str, page_size: int = 50) -> str:
        """
        æŸ¥çœ‹collectionçš„æ‰€æœ‰å†…å®¹å¹¶æ ¼å¼åŒ–ä¸ºMarkdown
        
        Args:
            collection_id: Collection ID
            page_size: æ¯é¡µæ•°æ®å—æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
        """
        try:
            collection_logger.info(f"å¼€å§‹æŸ¥çœ‹Collectionå†…å®¹ | ID: {collection_id[:8]}... | é¡µé¢å¤§å°: {page_size}")
            
            # è·å–collectionè¯¦ç»†ä¿¡æ¯ï¼ˆä½¿ç”¨æ–°çš„detailæ¥å£ï¼‰
            collection_detail = await self.api_client.get_collection_detail(collection_id)
            
            # è·å–æ‰€æœ‰æ•°æ®å—
            chunks = await self._get_all_chunks(collection_id, page_size)
            
            # è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥
            download_link = await self.api_client.get_file_download_link(collection_id)
            
            if not chunks:
                markdown_content = f"# Collectionå†…å®¹æŸ¥çœ‹\n\n**Collection ID:** `{collection_id}`\n\n"
                if collection_detail:
                    markdown_content += f"**åç§°:** {collection_detail.name}\n\n"
                markdown_content += "*æ­¤collectionä¸­æ²¡æœ‰æ•°æ®å—*\n\n"
                return markdown_content
            
            # ä½¿ç”¨ç»Ÿä¸€æ ¼å¼åŒ–å·¥å…·ç”Ÿæˆæ–‡æ¡£å¤´éƒ¨ï¼ˆåŒ…å«æ¥æºä¿¡æ¯ï¼‰
            header = FormatUtils.format_document_header(
                title="ğŸ“„ Collection å®Œæ•´å†…å®¹",
                collection_id=collection_id,
                source_name=collection_detail.name if collection_detail else "Unknown",
                download_link=download_link,
                collection_detail=collection_detail,
                chunk_count=len(chunks),
                dataset_id=chunks[0].dataset_id if chunks else None
            )
            
            # ç”Ÿæˆå†…å®¹éƒ¨åˆ†
            content_section = "## ğŸ“ æ–‡æ¡£å†…å®¹\n\n" + self._format_chunks_content(chunks)
            
            # è¿”å›å®Œæ•´å†…å®¹ï¼šå¤´éƒ¨ + å†…å®¹
            result = header + content_section
            
            collection_logger.info(f"Collectionå†…å®¹æŸ¥çœ‹å®Œæˆ | æ€»æ•°æ®å—: {len(chunks)}")
            return result
            
        except Exception as e:
            error_msg = str(e)
            collection_logger.error(f"æŸ¥çœ‹collectionå†…å®¹å¤±è´¥: {error_msg}", exc_info=True)
            
            # ä¸ºä¸åŒç±»å‹çš„é”™è¯¯æä¾›æ›´å‹å¥½çš„ä¿¡æ¯
            if "Collectionä¸å­˜åœ¨" in error_msg:
                return f"""# âŒ Collectionä¸å­˜åœ¨

**Collection ID:** `{collection_id}`

**é”™è¯¯ä¿¡æ¯:** Collectionä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥Collection IDæ˜¯å¦æ­£ç¡®ã€‚

**å»ºè®®è§£å†³æ–¹æ¡ˆ:**
1. ç¡®è®¤Collection IDæ˜¯å¦æ­£ç¡®
2. ä½¿ç”¨å…¶ä»–å·¥å…·æŸ¥çœ‹å¯ç”¨çš„Collectionåˆ—è¡¨
3. è”ç³»ç®¡ç†å‘˜ç¡®è®¤CollectionçŠ¶æ€
"""
            elif "HTTPè¯·æ±‚å¤±è´¥: 500" in error_msg:
                return f"""# âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯

**Collection ID:** `{collection_id}`

**é”™è¯¯ä¿¡æ¯:** APIæœåŠ¡å™¨è¿”å›500å†…éƒ¨é”™è¯¯

**å»ºè®®è§£å†³æ–¹æ¡ˆ:**
1. ç¨åé‡è¯•
2. æ£€æŸ¥APIæœåŠ¡å™¨çŠ¶æ€
3. è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—
"""
            else:
                return f"""# âŒ æŸ¥çœ‹Collectionå†…å®¹å¤±è´¥

**Collection ID:** `{collection_id}`

**é”™è¯¯ä¿¡æ¯:** {error_msg}

**å»ºè®®è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¡®è®¤APIé…ç½®æ˜¯å¦æ­£ç¡®
3. ç¨åé‡è¯•
"""
    
    async def _get_all_chunks(self, collection_id: str, page_size: int) -> List[DataChunk]:
        """è·å–collectionçš„æ‰€æœ‰æ•°æ®å—"""
        all_chunks = []
        offset = 0
        
        collection_logger.info(f"å¼€å§‹è·å–collection {collection_id} çš„æ‰€æœ‰æ•°æ®å—")
        
        while True:
            # è·å–å½“å‰é¡µçš„æ•°æ®
            chunks, has_more = await self.api_client.get_collection_chunks_page(collection_id, offset, page_size)
            
            if not chunks:
                break
            
            all_chunks.extend(chunks)
            collection_logger.debug(f"å·²è·å– {len(all_chunks)} ä¸ªæ•°æ®å— (å½“å‰é¡µ: {len(chunks)} ä¸ª)")
            
            if not has_more:
                break
                
            offset += page_size
        
        collection_logger.info(f"è·å–å®Œæˆï¼Œæ€»å…± {len(all_chunks)} ä¸ªæ•°æ®å—")
        return all_chunks
    
    def _format_chunks_content(self, chunks: List[DataChunk]) -> str:
        """æ ¼å¼åŒ–æ•°æ®å—å†…å®¹"""
        content_lines = []
        
        for i, chunk in enumerate(chunks, 1):
            content_lines.append(f"### æ•°æ®å— {i} (ç´¢å¼•: {chunk.chunk_index})")
            content_lines.append("")
            
            # å†…å®¹
            if chunk.q.strip():
                # å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²å¹¶æ·»åŠ 
                chunk_content_lines = chunk.q.strip().split('\n')
                for line in chunk_content_lines:
                    content_lines.append(line)
                content_lines.append("")
            
            # ç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
            if chunk.a.strip():
                content_lines.append("**ç­”æ¡ˆ:**")
                content_lines.append("")
                answer_lines = chunk.a.strip().split('\n')
                for line in answer_lines:
                    content_lines.append(line)
                content_lines.append("")
            
            content_lines.append("---")
            content_lines.append("")
        
        return '\n'.join(content_lines)
    
 