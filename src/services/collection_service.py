"""
Collectionç®¡ç†æœåŠ¡
"""

from typing import List
from urllib.parse import quote
from ..api_client import api_client
from ..models import DataChunk, CollectionInfo
from ..logger import collection_logger


class CollectionService:
    """Collectionç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.api_client = api_client
    
    async def view_collection_content(self, collection_id: str, page_size: int = 50) -> str:
        """
        æŸ¥çœ‹collectionçš„æ‰€æœ‰å†…å®¹å¹¶æ ¼å¼åŒ–ä¸ºMarkdown
        
        Args:
            collection_id: Collection ID
            page_size: æ¯é¡µæ•°æ®å—æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
        """
        try:
            collection_logger.info(f"å¼€å§‹æŸ¥çœ‹Collectionå†…å®¹ | ID: {collection_id[:8]}... | é¡µé¢å¤§å°: {page_size}")
            
            # è·å–collectionè¯¦ç»†ä¿¡æ¯ï¼ˆä½¿ç”¨æ–°çš„detailæ¥å£ï¼‰
            collection_detail = await self.api_client.get_collection_detail(collection_id)
            
            # è·å–æ‰€æœ‰æ•°æ®å—
            chunks = await self._get_all_chunks(collection_id, page_size)
            
            # è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥
            download_link = await self.api_client.get_file_download_link(collection_id)
            
            if not chunks:
                markdown_content = f"# Collectionå†…å®¹æŸ¥çœ‹\n\n**Collection ID:** `{collection_id}`\n\n"
                if collection_detail:
                    markdown_content += f"**åç§°:** {collection_detail.name}\n\n"
                markdown_content += "*æ­¤collectionä¸­æ²¡æœ‰æ•°æ®å—*\n\n"
                return markdown_content
            
            # ç”Ÿæˆç»Ÿä¸€çš„å†…å®¹æ–‡æœ¬
            main_content = self._format_chunks_content(chunks)
            
            # æ„å»ºæ¥æºä¿¡æ¯
            source_info = self._format_source_info(collection_id, collection_detail, download_link, chunks)
            
            # è¿”å›å®Œæ•´å†…å®¹ï¼šä¸»è¦å†…å®¹ + æ¥æºä¿¡æ¯
            result = main_content + source_info
            
            collection_logger.info(f"Collectionå†…å®¹æŸ¥çœ‹å®Œæˆ | æ€»æ•°æ®å—: {len(chunks)}")
            return result
            
        except Exception as e:
            collection_logger.error(f"æŸ¥çœ‹collectionå†…å®¹å¤±è´¥: {str(e)}", exc_info=True)
            return f"# é”™è¯¯\n\næŸ¥çœ‹collectionå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    async def _get_all_chunks(self, collection_id: str, page_size: int) -> List[DataChunk]:
        """è·å–collectionçš„æ‰€æœ‰æ•°æ®å—"""
        all_chunks = []
        offset = 0
        
        collection_logger.info(f"å¼€å§‹è·å–collection {collection_id} çš„æ‰€æœ‰æ•°æ®å—")
        
        while True:
            # è·å–å½“å‰é¡µçš„æ•°æ®
            chunks, has_more = await self.api_client.get_collection_chunks_page(collection_id, offset, page_size)
            
            if not chunks:
                break
            
            all_chunks.extend(chunks)
            collection_logger.debug(f"å·²è·å– {len(all_chunks)} ä¸ªæ•°æ®å— (å½“å‰é¡µ: {len(chunks)} ä¸ª)")
            
            if not has_more:
                break
                
            offset += page_size
        
        collection_logger.info(f"è·å–å®Œæˆï¼Œæ€»å…± {len(all_chunks)} ä¸ªæ•°æ®å—")
        return all_chunks
    
    def _format_chunks_content(self, chunks: List[DataChunk]) -> str:
        """æ ¼å¼åŒ–æ•°æ®å—å†…å®¹"""
        content_lines = []
        
        for i, chunk in enumerate(chunks, 1):
            content_lines.append(f"### æ•°æ®å— {i} (ç´¢å¼•: {chunk.chunk_index})")
            content_lines.append("")
            
            # å†…å®¹
            if chunk.q.strip():
                # å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²å¹¶æ·»åŠ 
                chunk_content_lines = chunk.q.strip().split('\n')
                for line in chunk_content_lines:
                    content_lines.append(line)
                content_lines.append("")
            
            # ç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
            if chunk.a.strip():
                content_lines.append("**ç­”æ¡ˆ:**")
                content_lines.append("")
                answer_lines = chunk.a.strip().split('\n')
                for line in answer_lines:
                    content_lines.append(line)
                content_lines.append("")
            
            content_lines.append("---")
            content_lines.append("")
        
        return '\n'.join(content_lines)
    
    def _format_source_info(self, collection_id: str, collection_detail: CollectionInfo, 
                           download_link: str, chunks: List[DataChunk]) -> str:
        """æ ¼å¼åŒ–æ¥æºä¿¡æ¯"""
        source_info = "\n\n## ğŸ“„ æ¥æºä¿¡æ¯\n\n"
        source_info += f"**Collection ID:** `{collection_id}`\n\n"
        
        if collection_detail:
            # ä½¿ç”¨æ–°çš„detailæ¥å£è·å–çš„å‡†ç¡®æ–‡ä»¶å
            source_name = collection_detail.name
            source_info += f"**æ¥æºæ–‡æ¡£:** {source_name}\n\n"
            source_info += f"**æ–‡æ¡£ç±»å‹:** {collection_detail.type}\n\n"
            
            # æ·»åŠ æ–‡ä»¶å¤§å°ä¿¡æ¯
            if collection_detail.raw_text_length:
                source_info += f"**æ–‡æ¡£å¤§å°:** {collection_detail.raw_text_length:,} å­—ç¬¦\n\n"
            
            # æ·»åŠ æ–‡ä»¶ä¸‹è½½é“¾æ¥
            if download_link:
                encoded_link = quote(download_link, safe=':/?#[]@!$&\'()*+,;=')
                source_info += f"**æ–‡ä»¶é“¾æ¥:** [{source_name}]({encoded_link})\n\n"
        
        source_info += f"**æ€»æ•°æ®å—æ•°é‡:** {len(chunks)}\n\n"
        source_info += f"**æ•°æ®é›†ID:** `{chunks[0].dataset_id if chunks else 'N/A'}`\n\n"
        
        return source_info 