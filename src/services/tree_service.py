"""
ç›®å½•æ ‘æœåŠ¡
"""

from typing import List, Dict, Any, Set
import asyncio
from ..api_client import api_client
from ..models import DatasetNode
from ..logger import tree_logger
from .permission_service import permission_service


class TreeService:
    """ç›®å½•æ ‘ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.api_client = api_client
    
    async def get_knowledge_base_tree(self, parent_id: str, search_value: str = "", deep: int = 4, userid: str = None) -> str:
        """
        è·å–çŸ¥è¯†åº“ç›®å½•æ ‘å¹¶æ ¼å¼åŒ–ä¸ºMarkdown
        
        Args:
            parent_id: çˆ¶çº§ç›®å½•ID
            search_value: æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒç©ºæ ¼åˆ†éš”çš„å¤šä¸ªå…³é”®è¯ï¼‰
            deep: ç›®å½•æ·±åº¦
            userid: ç”¨æˆ·IDï¼ˆç”¨äºæƒé™æ§åˆ¶ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
        """
        try:
            # å¤„ç†å¤šå…³é”®è¯æœç´¢
            keywords = self._parse_search_keywords(search_value)
            tree_logger.info(f"å¼€å§‹è·å–çŸ¥è¯†åº“ç›®å½•æ ‘ | çˆ¶çº§ID: {parent_id[:8]}... | æœç´¢è¯: {keywords} | æ·±åº¦: {deep}")
            
            if keywords:
                # ä½¿ç”¨å¹¶å‘APIè°ƒç”¨æœç´¢å¤šå…³é”®è¯
                tree_structure = await self._build_tree_with_concurrent_search(parent_id, keywords, deep)
            else:
                # æ— æœç´¢è¯ï¼Œè·å–å®Œæ•´ç›®å½•æ ‘
                tree_structure = await self._build_tree_recursively(parent_id, "", deep, 0)
            
            # åº”ç”¨æƒé™è¿‡æ»¤
            if userid and tree_structure:
                tree_structure = self._apply_permission_filter(tree_structure, userid)
            
            if not tree_structure:
                return f"# ğŸ“ çŸ¥è¯†åº“ç›®å½•æ ‘\n\n**æœç´¢æ¡ä»¶:** {search_value or 'æ— '}\n**æ·±åº¦:** {deep}\n\n*æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„å†…å®¹*\n"
            
            # æ ¼å¼åŒ–ä¸ºMarkdown
            markdown_content = self._format_tree_markdown_recursive(tree_structure, search_value, deep)
            
            total_nodes = self._count_total_nodes(tree_structure)
            tree_logger.info(f"ç›®å½•æ ‘è·å–å®Œæˆ | åŒ¹é…èŠ‚ç‚¹æ•°: {len(tree_structure)} | æ€»èŠ‚ç‚¹æ•°(å«å­èŠ‚ç‚¹): {total_nodes}")
            return markdown_content
            
        except Exception as e:
            tree_logger.error(f"è·å–çŸ¥è¯†åº“ç›®å½•æ ‘å¤±è´¥: {str(e)}", exc_info=True)
            return f"# âŒ é”™è¯¯\n\nè·å–çŸ¥è¯†åº“ç›®å½•æ ‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def _parse_search_keywords(self, search_value: str) -> List[str]:
        """è§£ææœç´¢å…³é”®è¯ï¼Œæ”¯æŒç©ºæ ¼åˆ†éš”"""
        if not search_value or not search_value.strip():
            return []
        
        # æŒ‰ç©ºæ ¼åˆ†å‰²å¹¶è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        keywords = [kw.strip() for kw in search_value.split() if kw.strip()]
        
        if len(keywords) > 1:
            tree_logger.info(f"æ£€æµ‹åˆ°å¤šä¸ªæœç´¢å…³é”®è¯: {keywords}")
        
        return keywords
    
    async def _build_tree_with_concurrent_search(self, parent_id: str, keywords: List[str], max_depth: int) -> List[dict]:
        """ä½¿ç”¨å¹¶å‘APIè°ƒç”¨å®ç°å¤šå…³é”®è¯æœç´¢"""
        tree_logger.info(f"å¼€å§‹å¹¶å‘å¤šå…³é”®è¯æœç´¢ | å…³é”®è¯æ•°: {len(keywords)}")
        
        # å¹¶å‘è°ƒç”¨åç«¯APIï¼Œæ¯ä¸ªå…³é”®è¯å•ç‹¬è¯·æ±‚
        async def search_single_keyword(keyword: str) -> List[dict]:
            try:
                tree_logger.info(f"æœç´¢å…³é”®è¯: '{keyword}'")
                # è°ƒç”¨åç«¯APIæœç´¢å•ä¸ªå…³é”®è¯
                nodes = await self.api_client.get_dataset_tree(parent_id, keyword, max_depth)
                
                # è½¬æ¢ä¸ºæ ‘ç»“æ„æ ¼å¼
                tree_structure = []
                for node in nodes:
                    node_data = {
                        'node': node,
                        'depth': 0,  # APIè¿”å›çš„æ˜¯æ‰å¹³ç»“æ„ï¼Œæ·±åº¦è®¾ä¸º0
                        'children': []
                    }
                    tree_structure.append(node_data)
                
                tree_logger.info(f"å…³é”®è¯ '{keyword}' æœç´¢åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹")
                return tree_structure
                
            except Exception as e:
                tree_logger.error(f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}")
                return []
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å…³é”®è¯æœç´¢
        import asyncio
        tasks = [search_single_keyword(keyword) for keyword in keywords]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶æ‰€æœ‰ç»“æœï¼Œå»é‡
        merged_nodes = {}  # ä½¿ç”¨å­—å…¸å»é‡ï¼Œkeyä¸ºnode.id
        total_found = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                tree_logger.error(f"å…³é”®è¯ '{keywords[i]}' æœç´¢å¼‚å¸¸: {result}")
                continue
            
            if isinstance(result, list):
                for node_data in result:
                    node_id = node_data['node'].id
                    if node_id not in merged_nodes:
                        merged_nodes[node_id] = node_data
                        total_found += 1
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        final_results = list(merged_nodes.values())
        
        tree_logger.info(f"å¹¶å‘æœç´¢å®Œæˆ | æ€»æ‰¾åˆ°: {total_found} ä¸ªå”¯ä¸€èŠ‚ç‚¹ | å»é‡å: {len(final_results)} ä¸ª")
        
        return final_results
    
    def _filter_nodes_by_keywords(self, tree_structure: List[dict], keywords: List[str]) -> List[dict]:
        """å®¢æˆ·ç«¯è¿‡æ»¤ï¼šæ ¹æ®å…³é”®è¯è¿‡æ»¤èŠ‚ç‚¹"""
        filtered_nodes = []
        
        def node_matches_keywords(node: DatasetNode, keywords: List[str]) -> bool:
            """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åŒ¹é…ä»»ä¸€å…³é”®è¯"""
            node_text = f"{node.name} {node.intro or ''}".lower()
            
            # åªè¦åŒ¹é…ä»»ä¸€å…³é”®è¯å°±ç®—åŒ¹é…
            for keyword in keywords:
                if keyword.lower() in node_text:
                    tree_logger.debug(f"èŠ‚ç‚¹åŒ¹é…æˆåŠŸ: '{node.name}' åŒ¹é…å…³é”®è¯ '{keyword}'")
                    return True
            
            # è°ƒè¯•ï¼šè®°å½•æœªåŒ¹é…çš„èŠ‚ç‚¹ï¼ˆä»…è®°å½•å‰å‡ ä¸ªï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼‰
            if len(keywords) <= 10:  # åªåœ¨å…³é”®è¯ä¸å¤ªå¤šæ—¶è®°å½•
                tree_logger.debug(f"èŠ‚ç‚¹æœªåŒ¹é…: '{node.name}' (æ–‡æœ¬: '{node_text[:50]}...') æœªåŒ¹é…å…³é”®è¯: {keywords[:3]}...")
            
            return False
        
        def filter_recursive(nodes: List[dict]) -> List[dict]:
            """é€’å½’è¿‡æ»¤èŠ‚ç‚¹"""
            result = []
            
            for node_data in nodes:
                node = node_data['node']
                children = node_data['children']
                
                # æ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦åŒ¹é…
                node_matches = node_matches_keywords(node, keywords)
                
                # é€’å½’è¿‡æ»¤å­èŠ‚ç‚¹
                filtered_children = filter_recursive(children) if children else []
                
                # å¦‚æœå½“å‰èŠ‚ç‚¹åŒ¹é…ï¼Œæˆ–è€…æœ‰åŒ¹é…çš„å­èŠ‚ç‚¹ï¼Œåˆ™ä¿ç•™
                if node_matches or filtered_children:
                    result.append({
                        'node': node,
                        'depth': node_data['depth'],
                        'children': filtered_children
                    })
                    
                    # è®°å½•åŒ¹é…åŸå› 
                    if node_matches:
                        tree_logger.debug(f"èŠ‚ç‚¹åŒ¹é…: {node.name}")
                    elif filtered_children:
                        tree_logger.debug(f"å­èŠ‚ç‚¹åŒ¹é…ï¼Œä¿ç•™çˆ¶èŠ‚ç‚¹: {node.name}")
            
            return result
        
        filtered_nodes = filter_recursive(tree_structure)
        
        # ç»Ÿè®¡åŒ¹é…ä¿¡æ¯
        total_matched = self._count_total_nodes(filtered_nodes)
        direct_matches = len(filtered_nodes)
        
        tree_logger.info(f"è¿‡æ»¤ç»“æœ | ç›´æ¥åŒ¹é…: {direct_matches} ä¸ª | æ€»è®¡(å«å­èŠ‚ç‚¹): {total_matched} ä¸ª")
        
        # è®°å½•æ¯ä¸ªå…³é”®è¯åœ¨åŸå§‹æ ‘ç»“æ„ä¸­çš„åŒ¹é…æƒ…å†µï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if direct_matches == 0:
            tree_logger.info("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šåœ¨åŸå§‹æ ‘ç»“æ„ä¸­æ£€æŸ¥å…³é”®è¯åŒ¹é…æƒ…å†µ:")
            for keyword in keywords:
                original_matches = self._count_keyword_matches(tree_structure, keyword)
                tree_logger.info(f"  å…³é”®è¯ '{keyword}' åœ¨åŸå§‹æ ‘ä¸­åŒ¹é…äº† {original_matches} ä¸ªèŠ‚ç‚¹")
            
            # æ˜¾ç¤ºå‰3ä¸ªèŠ‚ç‚¹æ ·æœ¬
            if len(tree_structure) > 0:
                tree_logger.info("ğŸ” å‰3ä¸ªèŠ‚ç‚¹æ ·æœ¬:")
                sample_count = min(3, len(tree_structure))
                for i in range(sample_count):
                    node = tree_structure[i]['node']
                    node_text = f"{node.name} {node.intro or ''}".lower()
                    tree_logger.info(f"  æ ·æœ¬{i+1}: '{node.name}' (ç±»å‹: {node.type}) (æ–‡æœ¬: '{node_text[:100]}...')")
        
        # è®°å½•è¿‡æ»¤åçš„åŒ¹é…æƒ…å†µ
        for keyword in keywords:
            keyword_matches = self._count_keyword_matches(filtered_nodes, keyword)
            tree_logger.info(f"å…³é”®è¯ '{keyword}' åœ¨è¿‡æ»¤ç»“æœä¸­åŒ¹é…äº† {keyword_matches} ä¸ªèŠ‚ç‚¹")
        
        return filtered_nodes
    
    def _count_keyword_matches(self, tree_structure: List[dict], keyword: str) -> int:
        """ç»Ÿè®¡ç‰¹å®šå…³é”®è¯çš„åŒ¹é…æ•°é‡"""
        count = 0
        
        def count_recursive(nodes: List[dict]):
            nonlocal count
            for node_data in nodes:
                node = node_data['node']
                node_text = f"{node.name} {node.intro or ''}".lower()
                if keyword.lower() in node_text:
                    count += 1
                
                if node_data['children']:
                    count_recursive(node_data['children'])
        
        count_recursive(tree_structure)
        return count
    
    async def _build_tree_recursively(self, parent_id: str, search_value: str, max_depth: int, current_depth: int) -> List[dict]:
        """é€’å½’æ„å»ºç›®å½•æ ‘ç»“æ„"""
        if current_depth >= max_depth:
            return []
        
        try:
            # è·å–å½“å‰å±‚çº§çš„èŠ‚ç‚¹ï¼ˆä¸ä½¿ç”¨æœåŠ¡å™¨ç«¯æœç´¢ï¼Œå› ä¸ºå®ƒä¸èµ·ä½œç”¨ï¼‰
            nodes = await self.api_client.get_dataset_tree(parent_id, "", 1)
            
            tree_structure = []
            for node in nodes:
                node_data = {
                    'node': node,
                    'depth': current_depth,
                    'children': []
                }
                
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ä¸”æœªè¾¾åˆ°æœ€å¤§æ·±åº¦ï¼Œé€’å½’è·å–å­èŠ‚ç‚¹
                if node.type == "folder" and current_depth < max_depth - 1:
                    node_data['children'] = await self._build_tree_recursively(
                        node.id, search_value, max_depth, current_depth + 1
                    )
                
                tree_structure.append(node_data)
            
            return tree_structure
            
        except Exception as e:
            tree_logger.warning(f"è·å–å±‚çº§ {current_depth} èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return []
    
    def _format_tree_markdown_recursive(self, tree_structure: List[dict], search_value: str, max_depth: int) -> str:
        """é€’å½’æ ¼å¼åŒ–ç›®å½•æ ‘ä¸ºMarkdown"""
        total_nodes = self._count_total_nodes(tree_structure)
        direct_matches = len(tree_structure)
        
        # è§£æå…³é”®è¯ç”¨äºå±•ç¤º
        keywords = self._parse_search_keywords(search_value)
        search_display = f"{keywords}" if keywords else "æ— "
        
        markdown_lines = [
            "# ğŸ“ çŸ¥è¯†åº“ç›®å½•æ ‘",
            "",
            f"**æœç´¢æ¡ä»¶:** {search_display}",
            f"**æœ€å¤§æ·±åº¦:** {max_depth}",
            f"**ç›´æ¥åŒ¹é…èŠ‚ç‚¹æ•°:** {direct_matches}",
            f"**æ€»èŠ‚ç‚¹æ•°(å«å­èŠ‚ç‚¹):** {total_nodes}",
            ""
        ]
        
        if keywords:
            markdown_lines.extend([
                "**æœç´¢è¯´æ˜:** æ”¯æŒå¤šå…³é”®è¯æœç´¢ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼Œä½¿ç”¨å®¢æˆ·ç«¯æ™ºèƒ½è¿‡æ»¤",
                "**è¿‡æ»¤é€»è¾‘:** åŒ¹é…èŠ‚ç‚¹åç§°å’Œæè¿°ä¸­çš„ä»»æ„å…³é”®è¯ï¼Œä¿ç•™åŒ¹é…èŠ‚ç‚¹åŠå…¶çˆ¶å­èŠ‚ç‚¹",
                ""
            ])
        
        # é€’å½’æ·»åŠ èŠ‚ç‚¹
        self._add_nodes_to_markdown(tree_structure, markdown_lines, 0, keywords)
        
        return '\n'.join(markdown_lines)
    
    def _add_nodes_to_markdown(self, tree_structure: List[dict], markdown_lines: List[str], depth: int, keywords: List[str] = None):
        """é€’å½’æ·»åŠ èŠ‚ç‚¹åˆ°Markdownï¼Œé«˜äº®åŒ¹é…çš„å…³é”®è¯"""
        for node_data in tree_structure:
            node = node_data['node']
            children = node_data['children']
            
            # è®¡ç®—ç¼©è¿›
            indent = "  " * depth
            
            # ç¡®å®šå›¾æ ‡
            icon = "ğŸ“š" if node.type == "dataset" else "ğŸ“"
            
            # é«˜äº®æ˜¾ç¤ºåŒ¹é…çš„å…³é”®è¯
            name_display = node.name
            intro_display = node.intro or ""
            
            if keywords:
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…å…³é”®è¯
                node_text = f"{node.name} {node.intro or ''}".lower()
                matched_keywords = [kw for kw in keywords if kw.lower() in node_text]
                
                if matched_keywords:
                    # æ·»åŠ åŒ¹é…æ ‡è¯†
                    match_indicator = f"ğŸ¯ **[åŒ¹é…: {', '.join(matched_keywords)}]**"
                    name_display = f"{node.name} {match_indicator}"
            
            # æ·»åŠ èŠ‚ç‚¹ä¿¡æ¯
            markdown_lines.append(f"{indent}- {icon} **{name_display}**")
            markdown_lines.append(f"{indent}  - ID: `{node.id}`")
            markdown_lines.append(f"{indent}  - ç±»å‹: {node.type}")
            
            # æ˜¾ç¤ºæè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
            if intro_display.strip():
                markdown_lines.append(f"{indent}  - æè¿°: {intro_display}")
            
            markdown_lines.append("")
            
            # é€’å½’æ·»åŠ å­èŠ‚ç‚¹
            if children:
                self._add_nodes_to_markdown(children, markdown_lines, depth + 1, keywords)
    
    def _count_total_nodes(self, tree_structure: List[dict]) -> int:
        """è®¡ç®—æ€»èŠ‚ç‚¹æ•°"""
        total = len(tree_structure)
        for node_data in tree_structure:
            total += self._count_total_nodes(node_data['children'])
        return total
    
    async def explore_folder_contents(self, folder_id: str, search_value: str = "", deep: int = 6, userid: str = None) -> str:
        """
        æ·±å…¥æ¢ç´¢æŒ‡å®šæ–‡ä»¶å¤¹çš„å†…å®¹
        
        ä¸“é—¨ç”¨äºæ¢ç´¢æ–‡ä»¶å¤¹å†…éƒ¨çš„æ‰€æœ‰çŸ¥è¯†åº“å’Œå­æ–‡ä»¶å¤¹ï¼Œæ”¯æŒæ›´æ·±å±‚æ¬¡çš„æœç´¢ã€‚
        å½“get_dataset_treeè¿”å›æ–‡ä»¶å¤¹æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·è¿›ä¸€æ­¥æ¢ç´¢æ–‡ä»¶å¤¹å†…å®¹ã€‚
        
        Args:
            folder_id: æ–‡ä»¶å¤¹IDï¼ˆä»get_dataset_treeç»“æœä¸­è·å–ï¼‰
            search_value: æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
            deep: æ¢ç´¢æ·±åº¦ï¼ˆ1-10ï¼Œé»˜è®¤6ï¼Œæ¯”æ™®é€šç›®å½•æ ‘æ›´æ·±ï¼‰
            userid: ç”¨æˆ·IDï¼ˆç”¨äºæƒé™æ§åˆ¶ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡ä»¶å¤¹å†…å®¹æŠ¥å‘Š
        """
        try:
            # å‚æ•°éªŒè¯
            if not folder_id or not folder_id.strip():
                return "âŒ è¯·æä¾›æœ‰æ•ˆçš„æ–‡ä»¶å¤¹ID"
            
            if deep < 1 or deep > 10:
                deep = 6
                tree_logger.warning(f"æ·±åº¦å‚æ•°è¶…å‡ºèŒƒå›´ï¼Œå·²è°ƒæ•´ä¸ºé»˜è®¤å€¼: {deep}")
            
            tree_logger.info(f"å¼€å§‹æ¢ç´¢æ–‡ä»¶å¤¹å†…å®¹ | æ–‡ä»¶å¤¹ID: {folder_id[:8]}... | æœç´¢è¯: '{search_value}' | æ·±åº¦: {deep}")
            
            # é¦–å…ˆéªŒè¯æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
            try:
                # å°è¯•è·å–æ–‡ä»¶å¤¹ä¿¡æ¯ï¼ˆæ·±åº¦1ï¼‰
                folder_info = await self.api_client.get_dataset_tree(folder_id, "", 1)
                if not folder_info:
                    return f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®\n\n**æ–‡ä»¶å¤¹ID:** `{folder_id}`"
            except Exception as e:
                tree_logger.error(f"éªŒè¯æ–‡ä»¶å¤¹å¤±è´¥: {e}")
                return f"âŒ æ— æ³•è®¿é—®æŒ‡å®šæ–‡ä»¶å¤¹: {str(e)}\n\n**æ–‡ä»¶å¤¹ID:** `{folder_id}`"
            
            # å¤„ç†æœç´¢å…³é”®è¯
            keywords = self._parse_search_keywords(search_value)
            
            # æ„å»ºæ–‡ä»¶å¤¹å†…å®¹æ ‘
            folder_contents = []
            search_fallback_used = False
            
            if keywords:
                # æœ‰æœç´¢è¯ï¼Œä½¿ç”¨å¹¶å‘APIæœç´¢
                folder_contents = await self._build_tree_with_concurrent_search(folder_id, keywords, deep)
                
                # æ™ºèƒ½å›é€€ï¼šå¦‚æœæœç´¢ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯æ–‡ä»¶å¤¹ååŒ¹é…ä½†å†…å®¹ä¸åŒ¹é…
                # è¿™æ—¶è‡ªåŠ¨ç§»é™¤æœç´¢å…³é”®è¯ï¼Œè·å–å®Œæ•´å†…å®¹
                if not folder_contents:
                    tree_logger.info(f"æœç´¢å…³é”®è¯ '{search_value}' æ— åŒ¹é…ç»“æœï¼Œå¯ç”¨æ™ºèƒ½å›é€€è·å–å®Œæ•´å†…å®¹")
                    folder_contents = await self._build_tree_recursively(folder_id, "", deep, 0)
                    search_fallback_used = True
            else:
                # æ— æœç´¢è¯ï¼Œè·å–å®Œæ•´å†…å®¹
                folder_contents = await self._build_tree_recursively(folder_id, "", deep, 0)
            
            # åº”ç”¨æƒé™è¿‡æ»¤
            if userid and folder_contents:
                folder_contents = self._apply_permission_filter(folder_contents, userid)
            
            if not folder_contents:
                search_info = f"æœç´¢æ¡ä»¶: '{search_value}'" if search_value else "æ— æœç´¢æ¡ä»¶"
                return f"""# ğŸ“ æ–‡ä»¶å¤¹å†…å®¹æ¢ç´¢

**æ–‡ä»¶å¤¹ID:** `{folder_id}`
**{search_info}**
**æ¢ç´¢æ·±åº¦:** {deep}

*æ­¤æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ²¡æœ‰åŒ¹é…çš„å†…å®¹*

ğŸ’¡ **å»ºè®®:**
- å°è¯•å‡å°‘æœç´¢å…³é”®è¯æˆ–ä½¿ç”¨æ›´é€šç”¨çš„è¯æ±‡
- å¢åŠ æ¢ç´¢æ·±åº¦å‚æ•°
- æ£€æŸ¥æ–‡ä»¶å¤¹æƒé™è®¾ç½®
"""
            
            # æ ¼å¼åŒ–ä¸ºè¯¦ç»†æŠ¥å‘Š
            report = self._format_folder_exploration_report(folder_id, folder_contents, search_value, deep, search_fallback_used)
            
            total_nodes = self._count_total_nodes(folder_contents)
            fallback_info = " (æ™ºèƒ½å›é€€)" if search_fallback_used else ""
            tree_logger.info(f"æ–‡ä»¶å¤¹æ¢ç´¢å®Œæˆ{fallback_info} | æ–‡ä»¶å¤¹ID: {folder_id[:8]}... | æ‰¾åˆ°èŠ‚ç‚¹: {len(folder_contents)} | æ€»è®¡: {total_nodes}")
            
            return report
            
        except Exception as e:
            tree_logger.error(f"æ¢ç´¢æ–‡ä»¶å¤¹å†…å®¹å¤±è´¥: {str(e)}", exc_info=True)
            return f"# âŒ æ¢ç´¢å¤±è´¥\n\n**æ–‡ä»¶å¤¹ID:** `{folder_id}`\n**é”™è¯¯ä¿¡æ¯:** {str(e)}\n\nè¯·æ£€æŸ¥æ–‡ä»¶å¤¹IDæ˜¯å¦æ­£ç¡®ï¼Œæˆ–è”ç³»ç®¡ç†å‘˜ã€‚"
    
    def _format_folder_exploration_report(self, folder_id: str, folder_contents: List[dict], search_value: str, deep: int, search_fallback_used: bool = False) -> str:
        """
        æ ¼å¼åŒ–æ–‡ä»¶å¤¹æ¢ç´¢æŠ¥å‘Š
        
        Args:
            folder_id: æ–‡ä»¶å¤¹ID
            folder_contents: æ–‡ä»¶å¤¹å†…å®¹æ ‘ç»“æ„
            search_value: æœç´¢æ¡ä»¶
            deep: æ¢ç´¢æ·±åº¦
            search_fallback_used: æ˜¯å¦ä½¿ç”¨äº†æ™ºèƒ½å›é€€
            
        Returns:
            æ ¼å¼åŒ–çš„æ¢ç´¢æŠ¥å‘Š
        """
        total_nodes = self._count_total_nodes(folder_contents)
        direct_items = len(folder_contents)
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„èŠ‚ç‚¹
        datasets_count = 0
        folders_count = 0
        
        def count_by_type(nodes: List[dict]):
            nonlocal datasets_count, folders_count
            for node_data in nodes:
                if node_data['node'].type == "dataset":
                    datasets_count += 1
                elif node_data['node'].type == "folder":
                    folders_count += 1
                
                if node_data['children']:
                    count_by_type(node_data['children'])
        
        count_by_type(folder_contents)
        
        # è§£æå…³é”®è¯
        keywords = self._parse_search_keywords(search_value)
        search_display = f"'{search_value}'" if search_value else "æ— "
        
        # ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨
        report_lines = [
            "# ğŸ“ æ–‡ä»¶å¤¹å†…å®¹æ·±åº¦æ¢ç´¢",
            "",
            f"**ç›®æ ‡æ–‡ä»¶å¤¹ID:** `{folder_id}`",
            f"**æœç´¢æ¡ä»¶:** {search_display}",
            f"**æ¢ç´¢æ·±åº¦:** {deep} å±‚",
        ]
        
        # å¦‚æœä½¿ç”¨äº†æ™ºèƒ½å›é€€ï¼Œæ·»åŠ è¯´æ˜
        if search_fallback_used:
            report_lines.extend([
                "",
                "ğŸ”„ **æ™ºèƒ½å›é€€è¯´æ˜:**",
                f"- åŸæœç´¢æ¡ä»¶ '{search_value}' åœ¨æ­¤æ–‡ä»¶å¤¹å†…æ— åŒ¹é…ç»“æœ",
                "- å·²è‡ªåŠ¨ç§»é™¤æœç´¢é™åˆ¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶å¤¹å®Œæ•´å†…å®¹",
                "- è¿™é€šå¸¸å‘ç”Ÿåœ¨æ–‡ä»¶å¤¹ååŒ¹é…ä½†å†…å®¹ä¸åŒ¹é…çš„æƒ…å†µ",
            ])
        
        report_lines.extend([
            "",
            "## ğŸ“Š æ¢ç´¢ç»Ÿè®¡",
            f"- **ç›´æ¥å­é¡¹:** {direct_items} ä¸ª",
            f"- **æ€»è®¡é¡¹ç›®:** {total_nodes} ä¸ª",
            f"- **çŸ¥è¯†åº“æ•°é‡:** {datasets_count} ä¸ª ğŸ“š",
            f"- **æ–‡ä»¶å¤¹æ•°é‡:** {folders_count} ä¸ª ğŸ“",
            ""
        ])
        
        if keywords and not search_fallback_used:
            report_lines.extend([
                "## ğŸ” æœç´¢è¯´æ˜",
                f"- **å…³é”®è¯:** {', '.join(keywords)}",
                "- **åŒ¹é…é€»è¾‘:** èŠ‚ç‚¹åç§°æˆ–æè¿°åŒ…å«ä»»ä¸€å…³é”®è¯",
                "- **ç»“æœåŒ…å«:** åŒ¹é…èŠ‚ç‚¹åŠå…¶å®Œæ•´çˆ¶å­å…³ç³»",
                ""
            ])
        
        # æ·»åŠ å†…å®¹è¯¦æƒ…
        if folder_contents:
            report_lines.extend([
                "## ğŸ“‹ è¯¦ç»†å†…å®¹",
                ""
            ])
            
            # é€’å½’æ·»åŠ èŠ‚ç‚¹ä¿¡æ¯
            self._add_nodes_to_markdown(folder_contents, report_lines, 0, keywords)
        
        # æ·»åŠ ä½¿ç”¨å»ºè®®
        report_lines.extend([
            "",
            "## ğŸ’¡ ä½¿ç”¨å»ºè®®",
            ""
        ])
        
        if datasets_count > 0:
            report_lines.extend([
                f"### ğŸ“š å‘ç° {datasets_count} ä¸ªçŸ¥è¯†åº“",
                "- ä½¿ç”¨ `search_dataset(dataset_id, text)` åœ¨ç‰¹å®šçŸ¥è¯†åº“ä¸­æœç´¢",
                "- ä½¿ç”¨ `multi_dataset_search([dataset_ids], query)` è·¨å¤šä¸ªçŸ¥è¯†åº“æœç´¢",
                ""
            ])
        
        if folders_count > 0:
            report_lines.extend([
                f"### ğŸ“ å‘ç° {folders_count} ä¸ªå­æ–‡ä»¶å¤¹", 
                "- ä½¿ç”¨ `explore_folder_contents(folder_id)` è¿›ä¸€æ­¥æ¢ç´¢å­æ–‡ä»¶å¤¹",
                "- å¯ä»¥å¢åŠ æ·±åº¦å‚æ•°è·å–æ›´æ·±å±‚æ¬¡çš„å†…å®¹",
                ""
            ])
        
        report_lines.extend([
            "### ğŸ” æœç´¢ä¼˜åŒ–",
            "- å¦‚æœç»“æœå¤ªå¤šï¼Œæ·»åŠ æ›´å…·ä½“çš„æœç´¢å…³é”®è¯",
            "- å¦‚æœç»“æœå¤ªå°‘ï¼Œå°è¯•æ›´é€šç”¨çš„å…³é”®è¯æˆ–å‡å°‘å…³é”®è¯æ•°é‡",
            "- ä½¿ç”¨ `expand_search_keywords(query)` è·å–å…³é”®è¯æ‰©å±•å»ºè®®",
            ""
        ])
        
        return '\n'.join(report_lines)
    
    def _format_tree_markdown(self, nodes: List[DatasetNode], search_value: str) -> str:
        """æ ¼å¼åŒ–ç›®å½•æ ‘ä¸ºMarkdownï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        markdown_lines = [
            "# ğŸ“ çŸ¥è¯†åº“ç›®å½•æ ‘",
            "",
            f"**æœç´¢æ¡ä»¶:** {search_value or 'æ— '}",
            f"**æ‰¾åˆ°é¡¹ç›®æ•°é‡:** {len(nodes)}",
            ""
        ]
        
        for node in nodes:
            # ç¡®å®šå›¾æ ‡
            icon = "ğŸ“š" if node.type == "dataset" else "ğŸ“"
            
            # æ·»åŠ èŠ‚ç‚¹ä¿¡æ¯ï¼ˆç®€åŒ–æ ¼å¼ï¼Œå»æ‰æƒé™ç­‰å†—ä½™ä¿¡æ¯ï¼‰
            markdown_lines.append(f"- {icon} **{node.name}**")
            markdown_lines.append(f"  - ID: `{node.id}`")
            markdown_lines.append(f"  - ç±»å‹: {node.type}")
            
            # åªæ˜¾ç¤ºæè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
            if node.intro and node.intro.strip():
                markdown_lines.append(f"  - æè¿°: {node.intro}")
            
            markdown_lines.append("")
        
        return '\n'.join(markdown_lines)
    
    def _apply_permission_filter(self, tree_structure: List[dict], userid: str) -> List[dict]:
        """
        åº”ç”¨æƒé™è¿‡æ»¤ï¼Œç§»é™¤ç”¨æˆ·æ— æƒé™è®¿é—®çš„å—é™æ•°æ®é›†
        
        Args:
            tree_structure: æ ‘ç»“æ„æ•°æ®
            userid: ç”¨æˆ·ID
            
        Returns:
            è¿‡æ»¤åçš„æ ‘ç»“æ„
        """
        if not tree_structure or not userid:
            return tree_structure
        
        filtered_structure = []
        
        for node_data in tree_structure:
            node = node_data['node']
            children = node_data['children']
            
            # æ£€æŸ¥å½“å‰èŠ‚ç‚¹æƒé™
            if node.type == 'dataset' and node.id in permission_service.config.restricted_datasets:
                # æ˜¯å—é™æ•°æ®é›†ï¼Œæ£€æŸ¥ç”¨æˆ·æƒé™
                if not permission_service.is_special_user(userid):
                    tree_logger.info(f"æƒé™è¿‡æ»¤: ç”¨æˆ· {userid} æ— æƒé™è®¿é—®å—é™æ•°æ®é›† {node.id[:8]}...")
                    continue  # è·³è¿‡è¿™ä¸ªå—é™æ•°æ®é›†
            
            # é€’å½’è¿‡æ»¤å­èŠ‚ç‚¹
            filtered_children = []
            if children:
                filtered_children = self._apply_permission_filter(children, userid)
            
            # æ·»åŠ è¿‡æ»¤åçš„èŠ‚ç‚¹
            filtered_structure.append({
                'node': node,
                'depth': node_data['depth'],
                'children': filtered_children
            })
        
        return filtered_structure 