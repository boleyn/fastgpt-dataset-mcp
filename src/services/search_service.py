"""
æœç´¢æœåŠ¡
"""

from typing import List
from urllib.parse import quote
from ..api_client import api_client
from ..models import SearchResult
from ..logger import search_logger
from .format_utils import FormatUtils
from .permission_service import permission_service


class SearchService:
    """æœç´¢ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.api_client = api_client
    
    async def search_knowledge_base_raw(self, dataset_id: str, query: str, limit: int = 10) -> List[SearchResult]:
        """
        æœç´¢çŸ¥è¯†åº“å¹¶è¿”å›åŸå§‹ç»“æœï¼ˆç”¨äºå…¶ä»–æœåŠ¡è°ƒç”¨ï¼‰
        
        Args:
            dataset_id: æ•°æ®é›†ID
            query: æœç´¢æŸ¥è¯¢
            limit: ç»“æœé™åˆ¶
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            search_logger.debug(f"åŸå§‹æœç´¢ | æ•°æ®é›†: {dataset_id[:8]}... | æŸ¥è¯¢: '{query}' | é™åˆ¶: {limit}")
            
            results = await self.api_client.search_dataset(dataset_id, query, limit)
            
            search_logger.debug(f"åŸå§‹æœç´¢å®Œæˆ | æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            search_logger.error(f"åŸå§‹æœç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []
    
    async def search_knowledge_base(self, dataset_id: str, text: str, limit: int = 10, userid: str = None) -> str:
        """
        æœç´¢çŸ¥è¯†åº“å¹¶æ ¼å¼åŒ–ä¸ºMarkdown
        
        Args:
            dataset_id: æ•°æ®é›†ID
            text: æœç´¢å…³é”®è¯
            limit: ç»“æœæ•°é‡é™åˆ¶
            userid: ç”¨æˆ·IDï¼ˆç”¨äºæƒé™æ§åˆ¶ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
        """
        try:
            search_logger.info(f"å¼€å§‹æœç´¢çŸ¥è¯†åº“ | æ•°æ®é›†: {dataset_id[:8]}... | å…³é”®è¯: '{text}' | é™åˆ¶: {limit}")
            
            # æ£€æŸ¥æƒé™
            if userid and not permission_service.has_dataset_access(userid, dataset_id):
                search_logger.warning(f"ç”¨æˆ· {userid} æ— æƒé™è®¿é—®å—é™æ•°æ®é›†: {dataset_id}")
                return f"# âŒ æƒé™ä¸è¶³\n\n**æ•°æ®é›†:** {dataset_id}\n\næ‚¨æ²¡æœ‰è®¿é—®æ­¤æ•°æ®é›†çš„æƒé™ã€‚è¯·è”ç³»ç®¡ç†å‘˜ã€‚"
            
            # å¤„ç†å¤šå…³é”®è¯æœç´¢
            search_results = await self._search_with_keywords(dataset_id, text, limit)
            
            if not search_results:
                return f"# æœç´¢ç»“æœ\n\n**æœç´¢å…³é”®è¯:** {text}\n\n**ç»“æœ:** æœªæ‰¾åˆ°ç›¸å…³å†…å®¹\n"
            
            # æ ¼å¼åŒ–ä¸ºMarkdown
            markdown_content = await self._format_search_results_markdown(search_results, text)
            
            search_logger.info(f"æœç´¢å®Œæˆ | æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
            return markdown_content
            
        except Exception as e:
            search_logger.error(f"æœç´¢çŸ¥è¯†åº“å¤±è´¥: {str(e)}", exc_info=True)
            return f"# æœç´¢å‡ºé”™\n\n**é”™è¯¯ä¿¡æ¯:** {str(e)}\n"
    
    async def _search_with_keywords(self, dataset_id: str, text: str, limit: int) -> List[SearchResult]:
        """å¤„ç†å¤šå…³é”®è¯æœç´¢"""
        # å¤„ç†ç©ºæ ¼åˆ†éš”çš„æœç´¢è¯
        if text and " " in text.strip():
            # å¦‚æœæœç´¢è¯åŒ…å«ç©ºæ ¼ï¼Œåˆ†åˆ«æœç´¢æ¯ä¸ªè¯ç„¶ååˆå¹¶ç»“æœ
            keywords = [kw.strip() for kw in text.split() if kw.strip()]
            search_logger.debug(f"æ£€æµ‹åˆ°å¤šä¸ªæœç´¢è¯: {keywords}")
            search_logger.debug("å°†åˆ†åˆ«æœç´¢æ¯ä¸ªè¯å¹¶åˆå¹¶ç»“æœï¼ˆMongoDBä¸æ”¯æŒç©ºæ ¼ORæœç´¢ï¼‰")
            
            all_results = []
            seen_ids = set()
            
            for keyword in keywords:
                search_logger.debug(f"æœç´¢å…³é”®è¯: '{keyword}' åœ¨æ•°æ®é›† {dataset_id}")
                results = await self.api_client.search_dataset(dataset_id, keyword, limit)
                
                # å»é‡åˆå¹¶ç»“æœ
                for item in results:
                    # ä½¿ç”¨å†…å®¹å’Œæ¥æºçš„ç»„åˆä½œä¸ºå”¯ä¸€æ ‡è¯†
                    unique_id = f"{item.id}_{item.collection_id}"
                    if unique_id not in seen_ids:
                        all_results.append(item)
                        seen_ids.add(unique_id)
            
            search_logger.info(f"åˆå¹¶ç»“æœå®Œæˆ | æ‰¾åˆ° {len(all_results)} ä¸ªå”¯ä¸€ç»“æœ")
            
            # æŒ‰è¯„åˆ†æ’åºå¹¶é™åˆ¶ç»“æœæ•°é‡
            all_results.sort(key=lambda x: sum(s.get("value", 0) for s in x.score), reverse=True)
            return all_results[:limit]
        else:
            # å•ä¸ªè¯æœç´¢
            return await self.api_client.search_dataset(dataset_id, text, limit)
    
    async def _format_search_results_markdown(self, search_results: List[SearchResult], text: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºMarkdown"""
        # å¤´éƒ¨ä¿¡æ¯
        markdown_content = f"# ğŸ” æœç´¢ç»“æœ\n\n**æœç´¢å…³é”®è¯:** {text}\n\n**æ‰¾åˆ° {len(search_results)} æ¡ç»“æœ**\n\n"
        
        for i, result in enumerate(search_results, 1):
            # è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥
            download_link = await self.api_client.get_file_download_link(result.collection_id)
            
            # è·å–collectionè¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºå‡†ç¡®çš„æ–‡ä»¶åï¼‰
            try:
                collection_detail = await self.api_client.get_collection_detail(result.collection_id)
            except:
                collection_detail = None
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼åŒ–å·¥å…·
            result_item = FormatUtils.format_search_result_item(
                result=result,
                index=i,
                download_link=download_link,
                collection_detail=collection_detail
            )
            
            markdown_content += result_item
        
        return markdown_content 